library(rpart.rplot)
library(rpart.rplot)
install.packages("rpart.plot")
library(data.table)
library(rpart)
library(rpart.rplot)
library(data.table)
library(rpart)
library(rpart.plot)
library(data.table)
open.srcfile(./labo/src/rpart/z101_PrimerModelo.R)
open.srcfile(/labo/src/rpart/z101_PrimerModelo.R)
open.srcfile(labo/src/rpart/z101_PrimerModelo.R)
library(ggplot2)
data("diamonds")
#modelo
mod_cdt <- lm(price ~ carat + depth + table, data = diamonds)
summary (mod_cdt)
coef(mod_cdt)
confint(mod_cdt)
vcov(mod_cdt)
summary((mod_cdt)$sigma)
deviance(mod_cdt)#sce
anova(mod_cdt)
mod0 <- lm(price ~ 1, diamonds)
anova(mod0, mod_cdt)
mod_ct <- lm(price ~ carat + table, diamonds) # modelo reducido
anova(mod_ct, mod_cdt)
data("mtcars")
force(mtcars)
View(valores)
View(mtcars)
View(mtcars)
mod_cdt <- lm(mpg ~ drat + disp + wt, data = mtcars)
summary (mod_cdt)
coef(mod_cdt)
confint(mod_cdt)
vcov(mod_cdt)
drat = 3.08
disp = 300
wt =4000
mod_cdt <- lm(mpg ~ drat + disp + wt, data = mtcars)
View(mtcars)
mod_cdt <- lm(mpg ~ drat + disp + wt, data = mtcars)
View(mod_cdt)
View(mod_ct)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
(rm(list = ls())) #limpiar vbles del enviroment
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
(rm(list = ls())) #limpiar vbles del enviroment
paquetes<-
c("psych", "ggplot2", "knitr", "skimr", "tidyr",
"pastecs", "FactoMineR", "grid",
"gridExtra", "ggfortify",  "factoextra",
"corrplot",  "dplyr", "DT", "tidyverse", "rpart")
#Instalar si no están
instalados<- paquetes %in% rownames(installed.packages())
if(any(instalados== FALSE)) {
install.packages(paquetes[!instalados])
}
library(janitor)
library(DT)
library(ggplot2)
library(skimr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(psych)
library(factoextra)
library(rpart)
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
(rm(list = ls())) #limpiar vbles del enviroment
paquetes<-
c("psych", "ggplot2", "knitr", "skimr", "tidyr",
"pastecs", "FactoMineR", "grid",
"gridExtra", "ggfortify",  "factoextra",
"corrplot",  "dplyr", "DT", "tidyverse", "rpart", "magrittr")
#Instalar si no están
instalados<- paquetes %in% rownames(installed.packages())
if(any(instalados== FALSE)) {
install.packages(paquetes[!instalados])
}
library(janitor)
library(DT)
library(ggplot2)
library(skimr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(psych)
library(factoextra)
library(rpart)
library(magrittr)
library(dplyr)
datos <- readRDS(file = "df_bcra_individuals.rds")
datatable(data = datos, filter = "top", list(scrollx = TRUE))
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
model_bc <- train(default ~ .,
data = dfArbolTrain,
trControl = caret.control,
tuneLength = 15)
library(rpart)
library(caret)
library(dplyr)
library(tidyr)
dfArbol <- data %>% select(-c("max_sit_mes_con_garantia", "peor_situacion_respuesta", "mora_mayor_30_dias", )) %>%
drop_na()
set.seed(12345)
partition<-createDataPartition(y=dfArbol$default, p=0.8, list = FALSE)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
(rm(list = ls())) #limpiar vbles del enviroment
paquetes<-
c("psych", "ggplot2", "knitr", "skimr", "tidyr",
"pastecs", "FactoMineR", "grid",
"gridExtra", "ggfortify",  "factoextra",
"corrplot",  "dplyr", "DT", "tidyverse", "rpart")
#Instalar si no están
instalados<- paquetes %in% rownames(installed.packages())
if(any(instalados== FALSE)) {
install.packages(paquetes[!instalados])
}
library(janitor)
library(DT)
library(ggplot2)
library(skimr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(psych)
library(factoextra)
library(rpart)
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
datos <- readRDS(file = "df_bcra_individuals.rds")
getwd()
setwd("C:/Users/scime/Desktop/MCD/Coursera/
Regresión Lineal en R")
setwd("C://Users/scime/Desktop/MCD/Coursera/
Regresión Lineal en R")
setwd("C://Users/scime/Desktop/MCD/Coursera/
Reg_Lineal")
setwd("C:/Users/scime/Desktop/MCD/Coursera/
Reg_Lineal")
setwd("C:/Users/scime/Desktop/MCD/Coursera/
Reg_Lineal")
getwd()
getwd()
setwd("C:/Users/scime/Desktop/MCD/Coursera/
Reg_Lineal")
#Manipulación de Datos
library(dplyr)
library(tidyr)
library(broom)
#Gráficos
library(ggplot2)
library(cowplot)  #no es indispensable
library(plotly)   #no es indispensable
#Datasets
library(UsingR)
# Estilo de gráficos
theme_set(theme_bw() + theme(text = element_text(size = 10)))
library(ggplot2)
data("diamond")
ggplot(diamond) +
aes(x = carat, y = price) +
geom_point()
#Rectas candidatas:
set.seed(109)
rectas <- tibble(
b0 = runif(min = -1000, max = 1500, n = 250),
b1 = runif(min = -10000, max = 5000, n = 250)
)
ggplot(data = diamond) +
aes(x = carat, y = price) +
geom_abline(aes(intercept = b0, slope = b1), data = rectas, alpha = 1/4) +
geom_point()
# Coeficientes de la recta
b0 <- -500
b1 <- 5000
# Diferencias entre los puntos y la recta
diferencias <- diamond$price - (b0 + b1 * diamond$carat)
round(diferencias)
#suma de las diferencias al cuadrado:
sum(diferencias^2) #Tiene mucho más sentido
cálculo de las diferencias para todas las rectas:
#cálculo de las diferencias para todas las rectas:
calcular_q <- function(b0, b1, x, y) {
diferencias <- y - (b0 + b1 * x)
sum(diferencias^2)
}
rectas$q <- mapply(
calcular_q,
rectas$b0,
rectas$b1,
MoreArgs = list(x = diamond$carat, y = diamond$price)
)
#grafico las 10 mejores rectas:
ggplot(data = diamond) +
aes(x = carat, y = price) +
geom_abline(aes(intercept = b0, slope = b1, color = q),
data = filter(rectas, rank(q) <= 10)) +
geom_point() +
scale_color_continuous(low = "green", high = "red")
# Redefino la función que calcula q para que sirva para optimización
calcular_q <- function(coefs, x, y) {
diferencias <- y - (coefs[1] + coefs[2] * x)
sum(diferencias^2)
solucion <- optim(c(-230, 3600), calcular_q, x = diamond$carat, y = diamond$price)
solucion$par
mod_cdt <- lm(price ~ carat + depth + table, data = diamonds)
summary (mod_cdt)
coef(mod_cdt)
confint(mod_cdt)
vcov(mod_cdt)
summary((mod_cdt)$sigma) #sigma: estimac de los errores
deviance(mod_cdt)#sce suma de cuadr. del error
anova(mod_cdt)# anal. tabla de la varianza
coef(mod_cdt)
lm(price ~ carat, data = diamond)
recta <-lm(price ~ carat, data = diamond)
summary(recta)
library(janitor)
summary(recta)
recta
lm(price ~ carat, data = diamond)
lm(price ~ carat, data = diamond)
lm(price ~ carat, data = diamond)
mod_cdt <- lm(price ~ carat + depth + table, data = diamonds)
summary (mod_cdt)
coef(mod_cdt)
confint(mod_cdt)
vcov(mod_cdt)
summary((mod_cdt)$sigma) #sigma: estimac de los errores
deviance(mod_cdt)#sce suma de cuadr. del error
anova(mod_cdt)# anal. tabla de la varianza
library(UsingR)
mod<- lm(price ~ carat, diamond)
coefficients(mod)
vcov(mod)
m1 <- lm(Sepal.Length - Sepal.Width, iris)
m1 <- lm(Sepal.Length ~ Sepal.Width, iris)
summary(m1)
m7<-lm(Sepal.length ~ Sepal.Width + Petal.Length + Petal.Width, iris)
#m7 el modelo más completo
m7<-lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, iris)
sigma(m1)^2
summary(m1)
summary(m1)$adj.r.squared
qpcr::PRESS(m1)$stat
olsrr::ols_mallows_cp(m1, m7)
extractAIC(m1)[2]
extractAIC(m1, k=nrow(iris))[2]
qpcr::PRESS(m7)$stat
qpcr::PRESS(m1)$stat
qpcr::PRESS(m1)$stat
summary(m1)$adj.r.squared
#PRESS
qpcR::PRESS(m1)$stat  #los :: es para no cargar el paquete con library
#PRESS
install.packages(qpcR)
#PRESS
library(qpcR)
install.packages("qpcR")
library(qpcR)
qpcR::PRESS(m1)$stat
qpcr::PRESS(m7)$stat
qpcRr::PRESS(m7)$stat
qpcR::PRESS(m7)$stat
olsrr::ols_mallows_cp(m1, m7)
install.packages("olsrr")
#CP Mallows
library(qpcR)
olsrr::ols_mallows_cp(m1, m7)
extractAIC(m1)[2]
extractAIC(m1, k=nrow(iris))[2]
m2 <- lm(Sepal.Length ~ Petal.Length, iris)
m3 <- lm(Sepal.Length ~ Petal.Width, iris)
m4 <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, iris)
m5 <- lm(Sepal.Length ~ Sepal.Width + Petal.Width, iris)
m6 <- lm(Sepal.Length ~ Petal.Length + Petal.Width, iris)
qpcR::PRESS(m1)$stat
extractAIC(m1, k=log(nrow(iris)))[2]
extractAIC(m7, k=log(nrow(iris)))[2]
library(UsingR)
library(leaps)
mejorsub <- regsubsets(medv ~ ., Boston, nvmax = 13)
resumen <- summary(mejorsub)
resumen
#Criterios de selección de modelos
resumen$cp
resumen$adjr2
resumen$bic
#Gráficos para comparar ajustes
plot(mejorsub, scale = "Cp")
plot(mejorsub, scale = "adjr2")
plot(mejorsub, scale = "bic")
#Cuál es el mejor según algún criterio
which.min(resumen$bic)
resumen$which[11, ]
#Cuál es el mejor según varios criterios
data.frame(
Adj.R2 = which.max(resumen$adjr2),
CP = which.min(resumen$cp),
BIC = which.min(resumen$bic)
)
x<-c(1,2,3,4,5,50)
y<-c(0.9,2.1,2.9,4.1,4.9,-10)
df<-data.frame(x,y)
library(ggplot2)
library(plotly)
ggplot(df)+
aes(x=x, y=y)+
geom_point()+
geom_smooth((method='modelo'))
ggplot(df)+
aes(x=x, y=y)+
geom_point()+
geom_smooth((method='lm'))
ggplot(df)+
aes(x=x, y=y)+
geom_point()+
geom_smooth((method="lm"))
datos <- tibble(
x = c(1:5, 50),
y = c(0.9, 2.1, 2.9, 4.1, 4.9, -10)
)
library(tidyr)
library(dplyr)
library(tidyr)
library(dplyr)
datos <- tibble(
x = c(1:5, 50),
y = c(0.9, 2.1, 2.9, 4.1, 4.9, -10)
)
ggplot(datos) +
aes(x = x, y = y) +
geom_point() +
geom_smooth(method = "lm")
ggplot(datos) +
aes(x = x, y = y) +
geom_point()
ggplot(datos) +
aes(x = x, y = y) +
geom_point() +
geom_smooth(method = "lm")
m<-lm(y ~ x, datos)
residuals((m))
summary(m)
rstandard(m)
rstudent(m)
hatvalues(m)
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
'devtools', 'uuid', 'digest'))
install.packages('IRkernel'
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
'devtools', 'uuid', 'digest'))
install.packages('IRkernel')
library( "IRkernel" )
IRkernel::installspec()
quit
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
options(scipen = 999)
rm(list=ls())
#Lista de paquetes a utilizar
listofpackages <- c("knitr","readr", "skimr", "corrplot", "psych", "dplyr","fastDummies","caTools", "corrplot", "leaps", "MASS", "qpcR", "car", "pROC")
#revisar e instalar librerias que no es están instaladas
newPackages <- listofpackages[ !(listofpackages %in% installed.packages()[, "Package"])]
if(length(newPackages)) install.packages(newPackages)
for (paquete in listofpackages) {
suppressMessages(library(paquete, character.only = TRUE))
}
df <- read_csv("data/mario.csv", show_col_types = FALSE)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
options(scipen = 999)
rm(list=ls())
#Lista de paquetes a utilizar
listofpackages <- c("knitr","readr", "skimr", "corrplot", "psych", "dplyr","fastDummies","caTools", "corrplot", "leaps", "MASS", "qpcR", "car", "glmnet","lattice", "caret", "pROC" )
#revisar e instalar librerias que no es están instaladas
newPackages <- listofpackages[ !(listofpackages %in% installed.packages()[, "Package"])]
if(length(newPackages)) install.packages(newPackages)
for (paquete in listofpackages) {
suppressMessages(library(paquete, character.only = TRUE))
}
df <- read_csv("data/mario.csv", show_col_types = FALSE)
source("~/.active-rstudio-document")
# Gradient Boosting of Decision Trees
# Regresion
# Stumps   , arboles de dos hojas
# limpio la memoria
rm(list = ls(all.names = TRUE)) # remove all objects
gc(full = TRUE) # garbage collection
require("data.table")
PARAM <- list()
PARAM$learning_rate <- 0.3
PARAM$num_iterations <- 5
archivo <- "https://storage.googleapis.com/open-courses/austral2023r-e52a/AustralitosVirtualitos.txt"
#------------------------------------------------------------------------------
options(error = function() {
traceback(20)
options(error = NULL)
stop("exiting after script error")
})
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# Aqui empieza el programa
# cargo el dataset
dataset <- fread(archivo)
# las variables independientes del dataset
campos_buenos <- setdiff(colnames(dataset), "Nota")
# el primer error es   ( Nota - promedio )
nota_mean <- dataset[, mean(Nota)]
dataset[, error := Nota - nota_mean]
# almaceno TODOS los splits de todos los arboles
tb_splits <- data.table(
iter = integer(),
campo = character(),
corte = numeric(),
gain = numeric(),
mejor = logical()
)
# almaceno el  rmse de los stumps
tb_stumps <- data.table(
iter = integer(),
rmse = numeric()
)
tb_stumps <- rbind(
tb_stumps,
list(0, dataset[, sqrt(mean(error * error))])
)
# avanzo por las iteraciones
for (iteracion in 1:PARAM$num_iterations) {
# recorro cada campo
for (campo in campos_buenos) {
# me quedo con < campo, error >
dcolumna <- dataset[
, list("error" = sum(error)),
list("valor" = get(campo))
]
# ordeno por los valores
setorder(dcolumna, valor)
# calculo los puntos de corte como el punto medio
dcolumna[, corte := frollmean(valor, 2, align = "left")]
# calculo el gain
dcolumna[, gain := cumsum(error)^2]
pos <- dcolumna[, which.max(abs(gain))]
reg <- dcolumna[pos]
# agrego el split a la tabla de splits
tb_splits <- rbind(
tb_splits,
list(
iteracion,
campo,
reg$corte,
abs(reg$gain),
FALSE
)
)
}
# busco el mejor split
tb_splits[iter == iteracion, mejor := .I == which.max(gain)]
reg <- tb_splits[iter == iteracion & mejor == TRUE]
# la hoja contribuye con LR * promedio
hoja1 <- dataset[get(reg$campo) < reg$corte, mean(error)]
dataset[get(reg$campo) < reg$corte, delta := -PARAM$learning_rate * hoja1]
hoja2 <- dataset[is.na(delta), mean(error)]
dataset[is.na(delta), delta := -PARAM$learning_rate * hoja2]
# modifico efectivamente el error = Boosting
dataset[, error := error + delta]
dataset[, delta := NULL]
tb_stumps <- rbind(
tb_stumps,
list(iteracion, dataset[, sqrt(mean(error * error))])
)
}
# imprimo
tb_stumps
tb_splits[mejor == TRUE]
source("C:/Users/scime/Desktop/MCD/Labo_I/LaboGit/labo2023r/src/workflow-inicial/z611_CA_reparar_dataset.r")
setwd("C:/Users/scime/Desktop/MCD/Labo_I/LaboGit/labo2023r/src/workflow-inicial")
